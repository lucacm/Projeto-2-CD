{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Thomas Bekhor\n",
    "\n",
    "Nome: Luca Machado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = \"Uber\"\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 590\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "msgs = list(dict.fromkeys(msgs))\n",
    "shuffle(msgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "    \n",
    "    #fecha o arquivo\n",
    "    writer.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1=RELEVANTE\n",
    "# 2=IRRELEVANTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lendo cada planilha separadamente do excel\n",
    "twitter_treinamento = pd.read_excel(io=\"./Uber.xlsx\",sheet_name=\"Treinamento\")\n",
    "twitter_teste = pd.read_excel(io=\"./Uber.xlsx\",sheet_name=\"Teste\")\n",
    "\n",
    "#aplicando a função cleanup no \"Teste\" e tirando as maiúsculas\n",
    "twitter_teste[\"Teste s/ pont.\"] = twitter_teste[\"Teste\"].apply(cleanup)\n",
    "twitter_teste=twitter_teste.drop(columns=\"Teste\")\n",
    "twitter_teste=twitter_teste[[\"Teste s/ pont.\", \"Relevância\"]]\n",
    "twitter_teste[\"Teste s/ pont.\"]=twitter_teste[\"Teste s/ pont.\"].str.lower()\n",
    "\n",
    "#aplicando a função cleanup no \"Treinamento\"  e tirando as maiúsculas\n",
    "twitter_treinamento[\"Treinamento s/ pont.\"] = twitter_treinamento[\"Treinamento\"].apply(cleanup)\n",
    "twitter_treinamento=twitter_treinamento.drop(columns=\"Treinamento\")\n",
    "twitter_treinamento=twitter_treinamento[[\"Treinamento s/ pont.\", \"Relevância\"]]\n",
    "twitter_treinamento[\"Treinamento s/ pont.\"]=twitter_treinamento[\"Treinamento s/ pont.\"].str.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando as palaras numa lista só\n",
    "series_treinamento=[]\n",
    "for i in twitter_treinamento[\"Treinamento s/ pont.\"]:\n",
    "    for n in i.split():\n",
    "        series_treinamento.append(n)\n",
    "series_treinamento\n",
    "\n",
    "#separando as palavras para os relevantes\n",
    "series_treinamento_rel=[]\n",
    "for i in twitter_treinamento[twitter_treinamento[\"Relevância\"]==1][\"Treinamento s/ pont.\"]:\n",
    "    for n in i.split():\n",
    "        series_treinamento_rel.append(n)\n",
    "\n",
    "#separando as palavras para os não relevantes\n",
    "series_treinamento_nrel=[]\n",
    "for i in twitter_treinamento[twitter_treinamento[\"Relevância\"]==0][\"Treinamento s/ pont.\"]:\n",
    "    for n in i.split():\n",
    "        series_treinamento_nrel.append(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uber              0.053293\n",
       "o                 0.030539\n",
       "e                 0.028743\n",
       "eu                0.023952\n",
       "de                0.022754\n",
       "que               0.022754\n",
       "                    ...   \n",
       "@itaecila         0.000299\n",
       "etc               0.000299\n",
       "amanha            0.000299\n",
       "first             0.000299\n",
       "sul               0.000299\n",
       "@oliverlani666    0.000299\n",
       "Length: 1266, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frequencia relativa nao relevantes\n",
    "frame_rel=pd.Series(series_treinamento_rel)\n",
    "frame_rel_relativo=frame_rel.value_counts(True)\n",
    "\n",
    "#frequencia relativa relevantes\n",
    "frame_nrel=pd.Series(series_treinamento_nrel)\n",
    "frame_nrel_relativo=frame_nrel.value_counts(True)\n",
    "\n",
    "#frequencia relativa total\n",
    "frame_total=pd.Series(series_treinamento)\n",
    "frame_total_relativo=frame_total.value_counts(True)\n",
    "\n",
    "frame_nrel_relativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(relevante|frase) > P(irrelevante|frase)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(relevante|frase) = \\frac{P(palavra1|relevante).P(palavra2|relevante).P(palavra3|relevante).P(relevante)}{P(frase)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(irrelevante|frase) = \\frac{P(palavra1|irrelevante).P(palavra2|irrelevante).P(palavra3|irrelevante).P(irrelevante)}{P(frase)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logo\n",
    "$P(relevante|frase)> P(irrelevante|frase)$ =\n",
    "$\\frac{P(palavra1|relevante).P(palavra2|relevante).P(palavra3|relevante).P(relevante)}{P(frase)}$ > $\\frac{P(palavra1|irrelevante).P(palavra2|irrelevante).P(palavra3|irrelevante).P(irrelevante)}{P(frase)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lista_prob_rel=[]\n",
    "lista_prob_nrel=[]\n",
    "\n",
    "tot=len(frame_total)\n",
    "\n",
    "for i in range(0,200):\n",
    "    prf=0.39*(1/len(frame_rel)+tot)\n",
    "    pif=0.61*(1/len(frame_nrel)+tot)\n",
    "    for x in twitter_teste[\"Teste s/ pont.\"][i].split():\n",
    "        if x in series_treinamento_rel:\n",
    "            prf=prf*frame_rel_relativo[x]\n",
    "        else:\n",
    "            prf=prf*(1/len(frame_rel)+tot)\n",
    "        if x in series_treinamento_nrel:    \n",
    "            pif=pif*frame_nrel_relativo[x]         \n",
    "        else:\n",
    "            pif=pif*(1/len(frame_nrel)+tot)\n",
    "            \n",
    "    lista_prob_rel.append(prf)\n",
    "    lista_prob_nrel.append(pif)\n",
    "    \n",
    "twitter_teste[\"Verificação\"]=-1\n",
    "for x in range(0,200):\n",
    "    if lista_prob_rel[x]>lista_prob_nrel[x]:\n",
    "        twitter_teste.iloc[x,2]=1\n",
    "    else:\n",
    "        twitter_teste.iloc[x,2]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Verificação</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevância</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.366071</td>\n",
       "      <td>0.633929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.465909</td>\n",
       "      <td>0.534091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Verificação         0         1\n",
       "Relevância                     \n",
       "0            0.366071  0.633929\n",
       "1            0.465909  0.534091"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=pd.crosstab(twitter_teste[\"Relevância\"], twitter_teste[\"Verificação\"], normalize=\"index\")\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de verdadeiros positivos: \n",
      "(mensagens relevantes e que são classificadas como relevantes)\n",
      "é 53.41%\n",
      "\n",
      "\n",
      "A probabilidade de falsos positivos \n",
      "(mensagens irrelevantes e que são classificadas como relevantes)\n",
      "é 63.39%\n",
      "\n",
      "\n",
      "A probabilidade de verdadeiros negativos \n",
      "(mensagens irrelevantes e que são classificadas como irrelevantes)\n",
      "é 36.61%\n",
      "\n",
      "\n",
      "A probabilidade de falsos negativos \n",
      "(mensagens relevantes e que são classificadas como irrelevantes)\n",
      "é 46.59%\n"
     ]
    }
   ],
   "source": [
    "verd_posit=round(final[1][1]*100,2)\n",
    "falso_posit=round(final[1][0]*100,2)\n",
    "verd_negat=round(final[0][0]*100,2)\n",
    "falso_negat=round(final[0][1]*100,2)\n",
    "\n",
    "print(\"A probabilidade de verdadeiros positivos: \\n(mensagens relevantes e que são classificadas como relevantes)\\né {0}%\" .format(verd_posit))\n",
    "print()\n",
    "print()\n",
    "print(\"A probabilidade de falsos positivos \\n(mensagens irrelevantes e que são classificadas como relevantes)\\né {0}%\" .format(falso_posit))\n",
    "print()\n",
    "print()\n",
    "print(\"A probabilidade de verdadeiros negativos \\n(mensagens irrelevantes e que são classificadas como irrelevantes)\\né {0}%\" .format(verd_negat))\n",
    "print()\n",
    "print()\n",
    "print(\"A probabilidade de falsos negativos \\n(mensagens relevantes e que são classificadas como irrelevantes)\\né {0}%\" .format(falso_negat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Por que não podemos usar o próprio classificador para gerar mais amostras de treinamento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classificador Naïve Bayes foi criado a partir de uma avaliação pessoal subjetiva de relevância para tweets com um tema em específico, no nosso caso o produto Uber. Isso leva a pensarmos que uma vez que o classificador foi montado ele não se atualiza e mantém sempre a mesma base de informação conforme a classificação de relevância que definimos anteriormente, assim o usuário que escolhesse usar nosso classificador Naïve Bayes estaria restrito à um tema específico, somente Uber e ainda sim estaria desatualizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propondo diferentes cenários de uso para o classificador Naïve Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a vasta variedade de temas e cenários disponíveis por aí, podemos aplicar a proposta do classificador Naïve Bayes para vários cenários que podem ajudar as pessoas no dia-a-dia, simplificar trabalhos, melhorar performance, entre outros. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  - Spam nos e-mails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um grande exemplo que temos é a classificação para as mensagens de spam no e-mail, por exemplo: sua função daria em ler e-mails novos que uma conta recebe e de acordo com sua programação identificar se aquele e-mail é spam ou não e consequentemente mandar diretamente aquele e-mail para a lixeira para o usuário não se preocupar ou perder seu tempo lendo aquele e-mail inútil. Lógico que há uma porcentagem de erro de o classificador classificar errôneamente, por isso é melhor guardar os e-mails em uma caixa de spams!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Transações bancárias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já pensou se repentinamente recebemos uma notificação da nossa agência bancária nos informando que uma certa transação de 100 mil reais foi aprovada no meio do dia? Que desespero! Outra utilidade em um cenário financeiro para nosso classificador Bayes é saber identificar se o valor de uma transação bancária corresponde ao perfil do nosso cliente. No sistema o classificador teria um perfil traçado do nosso cliente com base em suas transações antigas (evidência) e depois dado uma nova transação ele iria dizer se aquela transação bate com o perfil ou não, se não bater ela é automáticamente bloqueada e enviada uma solicitação ou notificação para o cliente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Previsão de trânsito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine ter que sair de casa e quando estiver no seu trajeto para o trabalho pegar aquele trânsito infernal que só causa estresse e ainda atrasa as pessoas para chegar em seus trabalhos e os estudantes nas faculdades, é insurpotável. Se análisarmos nesse cenário o classificador Naïve Bayes se mostra bastante útil uma vez que bem executado pode ler e identificar informações de maior fluxo de carros em avenidas. Por exemplo ele pode ser programado para coletar dados de todos os dias da semana, os horários e os locais que há uma maior quantidade de fluxo de carros, assim ele conseguirá obter qual a porcentagem dos fluxos serem maiores de acordo com os horários do dia e retornar a um usuário um bom horário para sair de casa sem que ele se atrase para seu compromisso ou pegue trânsito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como melhorar nosso classificador Naïve Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como falamos anteriormente o nosso classificador programado Naïve Bayes não é muito preciso e precisaria de melhorias para ser aperfeiçoado. Um dos pontos importantes em achar melhorias é primeiro identificar os problemas ou aonde que o nosso classificador falha, como por exemplo: sua precisão, atualizações, limpeza de caracteres.\n",
    "\n",
    "- Começando pela precisão de acerto do nosso classificador, um método eficaz seria aumentar a quantidade de tweets usados para treinamento classificando suas relevâncias, visto que 300 tweets para trabalhar como base pode ser considerado um número pequeno.\n",
    "\n",
    "\n",
    "- Assim como o aumento de tweets proposto, o aumento de categorias a serem analisadas como relevantes ou não podem ser importantes para a melhora do Bayes por que pode funcionar como um filtro a mais na hora de classificar. Os motivos de serem relevantes pode significar muito para o Naïve Bayes classificar como relevante ou não, por exemplo: se o motivo da relevância dos tweets do produto é gostar ou não pode ser perigoso pelo fato de ambas palavras estarem amplamente contidas nas duas categorias.\n",
    "\n",
    "\n",
    "- Saber diferenciar palavras que representam sarcasmo ou ironia ajuda bastante na hora de melhorar o classificador uma vez que se uma mensagem conter ironia ou sarcasmo pode confundir o classificador e ser marcada como relevante, uma vez que não era relevante.\n",
    "\n",
    "De acordo com pesquisas e estudos há uma forma de melhorar a performance do algoritmo Naïve Bayes para regressão através de combinação de atributos:\n",
    "\n",
    "_\"O algoritmo Naive Bayes para Regressão (NBR) usa a\n",
    "metodologia do Naive Bayes para tarefas de predição numéricas, modelando a\n",
    "distribuição de probabilidade do valor objetivo com estimadores de densidades por\n",
    "kernels. Entretanto, a incrível performance do Naive Bayes para problemas de\n",
    "classificação não é observada para problemas de regressão. Baseados em resultados\n",
    "experimentais que isolam a suposição de independência como a principal razão da\n",
    "pobre performance do NBR,concluíram que o algoritmo só deve ser\n",
    "aplicado a problemas de regressão quando a suposição de independência é verdadeira.\"_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
