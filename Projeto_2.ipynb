{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Thomas Bekhor\n",
    "\n",
    "Nome: Luca Machado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = \"Uber\"\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 590\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "msgs = list(dict.fromkeys(msgs))\n",
    "shuffle(msgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "    \n",
    "    #fecha o arquivo\n",
    "    writer.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1=RELEVANTE\n",
    "# 2=IRRELEVANTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    import string\n",
    "    #adicionando a remoção de @ nos tweets que não afeta a informação.\n",
    "    punctuation = '[!-.:?;@]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lendo cada planilha separadamente do excel\n",
    "twitter_treinamento = pd.read_excel(io=\"./Uber.xlsx\",sheet_name=\"Treinamento\")\n",
    "twitter_teste = pd.read_excel(io=\"./Uber.xlsx\",sheet_name=\"Teste\")\n",
    "\n",
    "#aplicando a função cleanup no \"Teste\" e tirando as maiúsculas\n",
    "twitter_teste[\"Teste s/ pont.\"] = twitter_teste[\"Teste\"].apply(cleanup)\n",
    "twitter_teste=twitter_teste.drop(columns=\"Teste\")\n",
    "twitter_teste=twitter_teste[[\"Teste s/ pont.\", \"Relevância\"]]\n",
    "twitter_teste[\"Teste s/ pont.\"]=twitter_teste[\"Teste s/ pont.\"].str.lower()\n",
    "\n",
    "#aplicando a função cleanup no \"Treinamento\"  e tirando as maiúsculas\n",
    "twitter_treinamento[\"Treinamento s/ pont.\"] = twitter_treinamento[\"Treinamento\"].apply(cleanup)\n",
    "twitter_treinamento=twitter_treinamento.drop(columns=\"Treinamento\")\n",
    "twitter_treinamento=twitter_treinamento[[\"Treinamento s/ pont.\", \"Relevância\"]]\n",
    "twitter_treinamento[\"Treinamento s/ pont.\"]=twitter_treinamento[\"Treinamento s/ pont.\"].str.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5664\n"
     ]
    }
   ],
   "source": [
    "#separando as palaras numa lista só\n",
    "series_treinamento=[]\n",
    "for i in twitter_treinamento[\"Treinamento s/ pont.\"]:\n",
    "    for n in i.split():\n",
    "        series_treinamento.append(n)\n",
    "series_treinamento\n",
    "\n",
    "#separando as palavras para os relevantes\n",
    "series_treinamento_rel=[]\n",
    "for i in twitter_treinamento[twitter_treinamento[\"Relevância\"]==1][\"Treinamento s/ pont.\"]:\n",
    "    for n in i.split():\n",
    "        series_treinamento_rel.append(n)\n",
    "\n",
    "#separando as palavras para os não relevantes\n",
    "series_treinamento_nrel=[]\n",
    "for i in twitter_treinamento[twitter_treinamento[\"Relevância\"]==0][\"Treinamento s/ pont.\"]:\n",
    "    for n in i.split():\n",
    "        series_treinamento_nrel.append(n)\n",
    "print(len(series_treinamento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequencia relativa nao relevantes\n",
    "frame_rel=pd.Series(series_treinamento_rel)\n",
    "frame_rel_relativo=frame_rel.value_counts(True)\n",
    "\n",
    "#frequencia relativa relevantes\n",
    "frame_nrel=pd.Series(series_treinamento_nrel)\n",
    "frame_nrel_relativo=frame_nrel.value_counts(True)\n",
    "\n",
    "#frequencia relativa total\n",
    "frame_total=pd.Series(series_treinamento)\n",
    "frame_total_relativo=frame_total.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uber          0.053293\n",
       "o             0.030539\n",
       "e             0.028743\n",
       "eu            0.023952\n",
       "de            0.022754\n",
       "que           0.022754\n",
       "                ...   \n",
       "viajes        0.000299\n",
       "friends       0.000299\n",
       "dê            0.000299\n",
       "famoso        0.000299\n",
       "heartbreak    0.000299\n",
       "empresa       0.000299\n",
       "Length: 1266, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testes\n",
    "frame_nrel_relativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uber           0.049053\n",
       "de             0.030981\n",
       "o              0.030551\n",
       "e              0.023236\n",
       "que            0.022375\n",
       "eu             0.021084\n",
       "                 ...   \n",
       "ganhe          0.000430\n",
       "promocional    0.000430\n",
       "realmente      0.000430\n",
       "aquele         0.000430\n",
       "óbvio          0.000430\n",
       "chá            0.000430\n",
       "Length: 899, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_rel_relativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04905335628227195"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conferindo a probabilidade da palavra ser relevante:\n",
    "frame_rel_relativo[\"uber\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053293413173652694"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conferindo a probabilidade da palavra ser relevante:\n",
    "frame_nrel_relativo[\"uber\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(relevante|frase) > P(irrelevante|frase)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(relevante|frase) = \\frac{P(palavra1|relevante).P(palavra2|relevante).P(palavra3|relevante).P(relevante)}{P(frase)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(irrelevante|frase) = \\frac{P(palavra1|irrelevante).P(palavra2|irrelevante).P(palavra3|irrelevante).P(irrelevante)}{P(frase)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logo\n",
    "$P(relevante|frase)> P(irrelevante|frase)$ =\n",
    "$\\frac{P(palavra1|relevante).P(palavra2|relevante).P(palavra3|relevante).P(relevante)}{P(frase)}$ > $\\frac{P(palavra1|irrelevante).P(palavra2|irrelevante).P(palavra3|irrelevante).P(irrelevante)}{P(frase)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste s/ pont.</th>\n",
       "      <th>Relevância</th>\n",
       "      <th>Verificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tava tão doida p ir embora daquele lugar q ent...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inclusive quando vi o da campus party quase fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>status  cantando sertanejo com o uber</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uber bom é uber que bate o carro no cara de trás</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e eu q pedi um uber aí tava nome de um homem l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trêm//metrô  4 30\\nuber  16 90\\n\\neu  quase o ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>decidi pegar uber</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>uber sem ar condicionado é sacanagi</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tô muito mau acostumada c uber  esse  fim de s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>meu uber  não  pq eu não vou ligar o ar né  tá...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>não  não dava tempo de dar meia volta  eu incl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>das vantagens de andar de uber  só o motorista...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Teste s/ pont.  Relevância  \\\n",
       "0    tava tão doida p ir embora daquele lugar q ent...           0   \n",
       "1    inclusive quando vi o da campus party quase fa...           0   \n",
       "2                status  cantando sertanejo com o uber           1   \n",
       "3     uber bom é uber que bate o carro no cara de trás           1   \n",
       "4    e eu q pedi um uber aí tava nome de um homem l...           1   \n",
       "5    trêm//metrô  4 30\\nuber  16 90\\n\\neu  quase o ...           1   \n",
       "..                                                 ...         ...   \n",
       "194                                  decidi pegar uber           0   \n",
       "195                uber sem ar condicionado é sacanagi           1   \n",
       "196  tô muito mau acostumada c uber  esse  fim de s...           0   \n",
       "197  meu uber  não  pq eu não vou ligar o ar né  tá...           1   \n",
       "198  não  não dava tempo de dar meia volta  eu incl...           1   \n",
       "199  das vantagens de andar de uber  só o motorista...           0   \n",
       "\n",
       "     Verificação  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "5              0  \n",
       "..           ...  \n",
       "194            0  \n",
       "195            0  \n",
       "196            0  \n",
       "197            0  \n",
       "198            0  \n",
       "199            0  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_teste=[]\n",
    "for i in twitter_teste[\"Teste s/ pont.\"]:\n",
    "    series_teste.append(i)\n",
    "\n",
    "twitter_teste[\"Verificação\"]=0\n",
    "#probabilidade total de relevantes\n",
    "prob_relevante= 117/300\n",
    "#probabilidade total de irrelevantes\n",
    "prob_nrelevante= 183/300\n",
    "\n",
    "\n",
    "\n",
    "for i in series_teste:\n",
    "    #probabilidade relevância na frase\n",
    "    prf=1\n",
    "    #probabilidade irelevância na frase\n",
    "    pif=1\n",
    "    for n in i.split():\n",
    "        if n in frame_rel:\n",
    "            prf*=prob_relevante*frame_rel_relativo[n]\n",
    "        elif n in frame_nrel:\n",
    "            pif*=prob_nrelevante*frame_nrel_relativo[n]\n",
    "        else:\n",
    "            prf=prf\n",
    "            pif=pif\n",
    "        if prf>pif:\n",
    "            twitter_teste[\"Verificação\"]=1 \n",
    "        \n",
    "twitter_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_teste=[]\n",
    "for i in twitter_teste[\"Teste s/ pont.\"]:\n",
    "    series_teste.append(i)\n",
    "\n",
    "#twitter_teste[\"Verificação\"]=0\n",
    "#probabilidade total de relevantes\n",
    "prob_relevante= 117/300\n",
    "#probabilidade total de irrelevantes\n",
    "prob_nrelevante= 183/300\n",
    "\n",
    "\n",
    "def calcula (series_teste):\n",
    "    x = list(tweet)\n",
    "    for i in x:\n",
    "        #probabilidade relevância na frase\n",
    "        prf=1\n",
    "        #probabilidade irelevância na frase\n",
    "        pif=1\n",
    "        for n in i.split():\n",
    "            if n in frame_rel:\n",
    "                prf*=prob_relevante*frame_rel_relativo[n]\n",
    "            elif n in frame_nrel:\n",
    "                pif*=prob_nrelevante*frame_nrel_relativo[n]\n",
    "            else:\n",
    "                prf=prf\n",
    "                pif=pif\n",
    "            if prf>pif:\n",
    "                return 1\n",
    "            else:\n",
    "                return 2 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_teste=[]\n",
    "for i in twitter_teste[\"Teste s/ pont.\"]:\n",
    "    series_teste.append(i)\n",
    "series_teste\n",
    "\n",
    "for i in series_teste:\n",
    "    for n in i.split():\n",
    "        if twitter_teste[\"Teste s/ pont.\"][\"Relevância\"]==1\n",
    "            for f in frame_rel_relativo[0:50]:\n",
    "                if n==f:\n",
    "                    twitter_teste[\"Verificação\"]=1\n",
    "                else:\n",
    "                    twitter_teste[\"Verificação\"]=0\n",
    "        else:\n",
    "            for f in frame_nrel_relativo[0:50]:\n",
    "                if n==f:\n",
    "                    twitter_teste[\"Verificação\"]=1\n",
    "                else:\n",
    "                    twitter_teste[\"Verificação\"]=0\n",
    "twitter_teste\n",
    "        \n",
    "#         for f in frame_nrel_relativo[0:50]:\n",
    "#             if n==f:\n",
    "#                 twitter_teste[\"Verificação\"]=1\n",
    "#             else:\n",
    "#                 twitter_teste[\"Verificação\"]=0\n",
    "\n",
    "\n",
    "# for i in twitter_teste[twitter_teste[\"Relevância\"]==1][\"Teste s/ pont.\"]:\n",
    "#     for n in i.split():\n",
    "#         for f in frame_rel_relativo[0:50]:\n",
    "#             if n==f:\n",
    "#                 twitter_teste[\"Verificação\"]=1\n",
    "#             else:\n",
    "#                 twitter_teste[\"Verificação\"]=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
