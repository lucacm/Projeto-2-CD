{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Thomas Bekhor\n",
    "\n",
    "Nome: Luca Machado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = \"Uber\"\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 590\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "msgs = list(dict.fromkeys(msgs))\n",
    "shuffle(msgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "    \n",
    "    #fecha o arquivo\n",
    "    writer.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1=RELEVANTE\n",
    "# 2=IRRELEVANTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lendo cada planilha separadamente do excel\n",
    "twitter_treinamento = pd.read_excel(io=\"./Uber.xlsx\",sheet_name=\"Treinamento\")\n",
    "twitter_teste = pd.read_excel(io=\"./Uber.xlsx\",sheet_name=\"Teste\")\n",
    "\n",
    "#aplicando a função cleanup no \"Teste\" e tirando as maiúsculas\n",
    "twitter_teste[\"Teste s/ pont.\"] = twitter_teste[\"Teste\"].apply(cleanup)\n",
    "twitter_teste=twitter_teste.drop(columns=\"Teste\")\n",
    "twitter_teste=twitter_teste[[\"Teste s/ pont.\", \"Relevância\"]]\n",
    "twitter_teste[\"Teste s/ pont.\"]=twitter_teste[\"Teste s/ pont.\"].str.lower()\n",
    "\n",
    "#aplicando a função cleanup no \"Treinamento\"  e tirando as maiúsculas\n",
    "twitter_treinamento[\"Treinamento s/ pont.\"] = twitter_treinamento[\"Treinamento\"].apply(cleanup)\n",
    "twitter_treinamento=twitter_treinamento.drop(columns=\"Treinamento\")\n",
    "twitter_treinamento=twitter_treinamento[[\"Treinamento s/ pont.\", \"Relevância\"]]\n",
    "twitter_treinamento[\"Treinamento s/ pont.\"]=twitter_treinamento[\"Treinamento s/ pont.\"].str.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando as palaras numa lista só\n",
    "series_treinamento=[]\n",
    "for i in twitter_treinamento[\"Treinamento s/ pont.\"]:\n",
    "    for n in i.split():\n",
    "        series_treinamento.append(n)\n",
    "series_treinamento\n",
    "\n",
    "#separando as palavras para os relevantes\n",
    "series_treinamento_rel=[]\n",
    "for i in twitter_treinamento[twitter_treinamento[\"Relevância\"]==1][\"Treinamento s/ pont.\"]:\n",
    "    for n in i.split():\n",
    "        series_treinamento_rel.append(n)\n",
    "\n",
    "#separando as palavras para os não relevantes\n",
    "series_treinamento_nrel=[]\n",
    "for i in twitter_treinamento[twitter_treinamento[\"Relevância\"]==0][\"Treinamento s/ pont.\"]:\n",
    "    for n in i.split():\n",
    "        series_treinamento_nrel.append(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uber          0.053293\n",
       "o             0.030539\n",
       "e             0.028743\n",
       "eu            0.023952\n",
       "de            0.022754\n",
       "que           0.022754\n",
       "                ...   \n",
       "casaa         0.000299\n",
       "aplicativo    0.000299\n",
       "2min          0.000299\n",
       "branco        0.000299\n",
       "terminou      0.000299\n",
       "z             0.000299\n",
       "Length: 1266, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frequencia relativa nao relevantes\n",
    "frame_rel=pd.Series(series_treinamento_rel)\n",
    "frame_rel_relativo=frame_rel.value_counts(True)\n",
    "\n",
    "#frequencia relativa relevantes\n",
    "frame_nrel=pd.Series(series_treinamento_nrel)\n",
    "frame_nrel_relativo=frame_nrel.value_counts(True)\n",
    "\n",
    "#frequencia relativa total\n",
    "frame_total=pd.Series(series_treinamento)\n",
    "frame_total_relativo=frame_total.value_counts(True)\n",
    "\n",
    "frame_nrel_relativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(relevante|frase) > P(irrelevante|frase)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(relevante|frase) = \\frac{P(palavra1|relevante).P(palavra2|relevante).P(palavra3|relevante).P(relevante)}{P(frase)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(irrelevante|frase) = \\frac{P(palavra1|irrelevante).P(palavra2|irrelevante).P(palavra3|irrelevante).P(irrelevante)}{P(frase)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logo\n",
    "$P(relevante|frase)> P(irrelevante|frase)$ =\n",
    "$\\frac{P(palavra1|relevante).P(palavra2|relevante).P(palavra3|relevante).P(relevante)}{P(frase)}$ > $\\frac{P(palavra1|irrelevante).P(palavra2|irrelevante).P(palavra3|irrelevante).P(irrelevante)}{P(frase)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste s/ pont.</th>\n",
       "      <th>Relevância</th>\n",
       "      <th>Verificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tava tão doida p ir embora daquele lugar q ent...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inclusive quando vi o da campus party quase fa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>status  cantando sertanejo com o uber</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uber bom é uber que bate o carro no cara de trás</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e eu q pedi um uber aí tava nome de um homem l...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trêm//metrô  4 30\\nuber  16 90\\n\\neu  quase o ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decidi pegar uber</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uber sem ar condicionado é sacanagi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tô muito mau acostumada c uber  esse  fim de semana c hj gastei 200 e pouco  perai eu tô ficando louca</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meu uber  não  pq eu não vou ligar o ar né  tá bom esse ventinho  eu  sim  capaz  meu uber dps de 3 min  é vou ligar o ar né  não dá</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>não  não dava tempo de dar meia volta  eu inclusive paguei o ingresso  mas ele só garantia lugar até 19 35  eu ia chegar no mínimo 19 45  correndo risco sério de estar lotada  fora  quanto essa tour de uber ia me custar sério  que raiva de mim</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>das vantagens de andar de uber  só o motorista te vê chorando  bem ao contrário do busão</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       Teste s/ pont.  \\\n",
       "0                                                   tava tão doida p ir embora daquele lugar q ent...   \n",
       "1                                                   inclusive quando vi o da campus party quase fa...   \n",
       "2                                                               status  cantando sertanejo com o uber   \n",
       "3                                                    uber bom é uber que bate o carro no cara de trás   \n",
       "4                                                   e eu q pedi um uber aí tava nome de um homem l...   \n",
       "5                                                   trêm//metrô  4 30\\nuber  16 90\\n\\neu  quase o ...   \n",
       "...                                                                                               ...   \n",
       "decidi pegar uber                                                                                 NaN   \n",
       "uber sem ar condicionado é sacanagi                                                               NaN   \n",
       "tô muito mau acostumada c uber  esse  fim de se...                                                NaN   \n",
       "meu uber  não  pq eu não vou ligar o ar né  tá ...                                                NaN   \n",
       "não  não dava tempo de dar meia volta  eu inclu...                                                NaN   \n",
       "das vantagens de andar de uber  só o motorista ...                                                NaN   \n",
       "\n",
       "                                                    Relevância  Verificação  \n",
       "0                                                          0.0          NaN  \n",
       "1                                                          0.0          NaN  \n",
       "2                                                          1.0          NaN  \n",
       "3                                                          1.0          NaN  \n",
       "4                                                          1.0          NaN  \n",
       "5                                                          1.0          NaN  \n",
       "...                                                        ...          ...  \n",
       "decidi pegar uber                                          NaN          0.0  \n",
       "uber sem ar condicionado é sacanagi                        NaN          0.0  \n",
       "tô muito mau acostumada c uber  esse  fim de se...         NaN          1.0  \n",
       "meu uber  não  pq eu não vou ligar o ar né  tá ...         NaN          1.0  \n",
       "não  não dava tempo de dar meia volta  eu inclu...         NaN          0.0  \n",
       "das vantagens de andar de uber  só o motorista ...         NaN          1.0  \n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lista_prob_rel=[]\n",
    "lista_prob_nrel=[]\n",
    "\n",
    "#laplace=\n",
    "\n",
    "for i in range(0,200):\n",
    "    prf=0.39\n",
    "    pif=0.61\n",
    "    for x in twitter_teste[\"Teste s/ pont.\"][i].split():\n",
    "        if x in series_treinamento_rel:\n",
    "            prf=prf*frame_rel_relativo[x]\n",
    "        if x in series_treinamento_nrel:    \n",
    "            pif=pif*frame_nrel_relativo[x]         \n",
    "        else:\n",
    "            prf=prf*2\n",
    "            pif=pif*2\n",
    "            \n",
    "    lista_prob_rel.append(prf)\n",
    "    lista_prob_nrel.append(pif)\n",
    "    \n",
    "for x in range(0,200):\n",
    "    if lista_prob_rel[x]>lista_prob_nrel[x]:\n",
    "        twitter_teste.loc[twitter_teste[\"Teste s/ pont.\"][x],\"Verificação\"]=1#problema2\n",
    "    else:\n",
    "        twitter_teste.loc[twitter_teste[\"Teste s/ pont.\"][x],\"Verificação\"]=0\n",
    "twitter_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
